import os
import random
import numpy as np
import matplotlib.pyplot as plt
import librosa
import soundfile as sf
from tqdm import tqdm

import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report

# ---------------------
# CONFIG
# ---------------------
DATA_ROOT = "dataset/dataset"   # dataset/<CLASS>/*.wav

SR = 16000
DURATION = 2.0
TARGET_LEN = int(SR * DURATION)

N_FFT = 512
HOP = 160
WIN = 400

N_MELS = 96

RMS_TARGET = 0.02

AUGS = 4

random.seed(42)
np.random.seed(42)
tf.random.set_seed(42)

# ---------------------
# CLASSES & HELPERS
# ---------------------
classes = sorted([
    d for d in os.listdir(DATA_ROOT)
    if os.path.isdir(os.path.join(DATA_ROOT, d))
])
print("Detected classes:", classes)

def list_wavs(root):
    arr = []
    for cl in classes:
        folder = os.path.join(root, cl)
        for fn in os.listdir(folder):
            if fn.lower().endswith(".wav"):
                arr.append((os.path.join(folder, fn), cl))
    return arr

def rms(y):
    return np.sqrt(np.mean(y**2))

def apply_gain_normalization(y, target=RMS_TARGET):
    cur = rms(y) + 1e-8
    return y * (target / cur)

def pad_trim(y, target_len=TARGET_LEN):
    if len(y) < target_len:
        y = np.pad(y, (0, target_len - len(y)))
    return y[:target_len]

# ---------------------
# AUGMENTATION (fixed resample usage, safe pitch_shift)
# ---------------------
def augment_waveform(y, sr=SR):
    # Time shift
    if random.random() < 0.5:
        shift = int(random.uniform(-0.15, 0.15) * sr)
        y = np.roll(y, shift)
        if shift > 0:
            y[:shift] = 0
        else:
            y[shift:] = 0

    # Pitch shift (safe)
    if random.random() < 0.5:
        steps = random.uniform(-1.0, 1.0)
        try:
            y = librosa.effects.pitch_shift(y, sr=sr, n_steps=steps)
        except Exception:
            # in case of very short arrays or other failures, skip pitch shift
            pass

    # Time stretch via resample (correct keyword args)
    if random.random() < 0.5:
        rate = random.uniform(0.9, 1.1)
        target_sr = int(sr * rate)
        # Resample from sr -> target_sr, then pad/trim back to SR length
        try:
            stretched = librosa.resample(y=y, orig_sr=sr, target_sr=target_sr)
            # resample back to SR so downstream expects SR
            if target_sr != sr:
                stretched = librosa.resample(y=stretched, orig_sr=target_sr, target_sr=sr)
            y = pad_trim(stretched)
        except Exception:
            # if anything fails, keep original
            pass

    # Add noise
    if random.random() < 0.5:
        noise = np.random.normal(0, random.uniform(0.001, 0.01), len(y))
        y = y + noise

    return y

# ---------------------
# FEATURES (correct librosa call)
# ---------------------
def waveform_to_melspec(y, sr=SR):
    mel = librosa.feature.melspectrogram(
        y=y,
        sr=sr,
        n_fft=N_FFT,
        hop_length=HOP,
        win_length=WIN,
        n_mels=N_MELS,
        fmin=20,
        fmax=sr // 2
    )

    mel_db = librosa.power_to_db(mel, ref=np.max)

    # normalize
    mel_db = (mel_db - mel_db.mean()) / (mel_db.std() + 1e-6)

    return mel_db.astype(np.float32)

# ---------------------
# LOAD + PREPROCESS
# ---------------------
entries = list_wavs(DATA_ROOT)
print("Total WAV files:", len(entries))

X, y = [], []

for path, label in tqdm(entries):
    wav, sr = sf.read(path)   # sf.read returns (data, samplerate)

    # If multi-channel, convert to mono
    if wav.ndim > 1:
        wav = wav.mean(axis=1)

    # If file sample rate differs from SR, resample correctly
    if sr != SR:
        try:
            wav = librosa.resample(y=wav, orig_sr=sr, target_sr=SR)
            sr = SR
        except Exception:
            # fallback: use numpy resampling via librosa load (safer to re-load)
            wav, sr = librosa.load(path, sr=SR)

    wav = pad_trim(wav)
    wav = apply_gain_normalization(wav)

    # original
    X.append(waveform_to_melspec(wav, sr=SR))
    y.append(label)

    # augmented
    for _ in range(AUGS):
        aug = augment_waveform(wav.copy(), sr=SR)
        aug = apply_gain_normalization(aug)
        X.append(waveform_to_melspec(aug, sr=SR))
        y.append(label)

# convert arrays
X = np.array(X, dtype=np.float32)
y = np.array(y)

print("Feature shape:", X.shape)

# ---------------------
# LABELS & SPLIT
# ---------------------
le = LabelEncoder()
y_enc = le.fit_transform(y)
labels = list(le.classes_)
print("Label order:", labels)

X_train, X_test, y_train, y_test = train_test_split(
    X, y_enc, test_size=0.2, random_state=42, stratify=y_enc
)

X_train = X_train[..., np.newaxis]
X_test = X_test[..., np.newaxis]
input_shape = X_train.shape[1:]
print("Input shape:", input_shape)

# ---------------------
# MODEL (CRNN w/ BiGRU) - use backend.int_shape for reshape dims
# ---------------------
inp = layers.Input(shape=input_shape)

x = layers.Conv2D(32, 3, padding="same", activation="relu")(inp)
x = layers.BatchNormalization()(x)
x = layers.MaxPool2D(2)(x)

x = layers.Conv2D(64, 3, padding="same", activation="relu")(x)
x = layers.BatchNormalization()(x)
x = layers.MaxPool2D(2)(x)

x = layers.Conv2D(128, 3, padding="same", activation="relu")(x)
x = layers.BatchNormalization()(x)
x = layers.MaxPool2D(2)(x)

# reshape for GRU - use static int shape
x = layers.Permute((2, 1, 3))(x)
shape_after = tf.keras.backend.int_shape(x)  # (None, time, freq, channels)
ts = shape_after[1]
fd = shape_after[2] * shape_after[3]
x = layers.Reshape((ts, fd))(x)

x = layers.Bidirectional(layers.GRU(128, return_sequences=False))(x)

x = layers.Dense(128, activation="relu")(x)
x = layers.Dropout(0.3)(x)

out = layers.Dense(len(labels), activation="softmax")(x)

model = models.Model(inp, out)
model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])

model.summary()

# ---------------------
# TRAIN
# ---------------------
callbacks = [
    tf.keras.callbacks.EarlyStopping(patience=6, restore_best_weights=True),
    tf.keras.callbacks.ModelCheckpoint("best_model.h5", save_best_only=True)
]

history = model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=60,
    batch_size=8,
    callbacks=callbacks
)

# ---------------------
# EVAL + REPORT
# ---------------------
train_loss, train_acc = model.evaluate(X_train, y_train, verbose=0)
val_loss, val_acc = model.evaluate(X_test, y_test, verbose=0)

print(f"Training Accuracy: {train_acc*100:.2f}%")
print(f"Validation Accuracy: {val_acc*100:.2f}%")

y_pred = np.argmax(model.predict(X_test), axis=1)

print(classification_report(y_test, y_pred, target_names=labels))

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(7,6))
plt.imshow(cm, cmap="Blues")
plt.title("Confusion Matrix")
plt.colorbar()
plt.xticks(range(len(labels)), labels, rotation=45)
plt.yticks(range(len(labels)), labels)
plt.tight_layout()
plt.show()

# ---------------------
# EXPORT TFLITE + LABELS
# ---------------------
try:
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    converter.target_spec.supported_ops = [
        tf.lite.OpsSet.TFLITE_BUILTINS,
        tf.lite.OpsSet.SELECT_TF_OPS
    ]
    # Some TF versions expose this attribute; guard it
    try:
        converter._experimental_lower_tensor_list_ops = False
    except Exception:
        pass
    converter.optimizations = [tf.lite.Optimize.DEFAULT]

    tflite = converter.convert()
    with open("model.tflite", "wb") as f:
        f.write(tflite)
    print("Exported model.tflite")
except Exception as e:
    print("TFLite export failed:", e)

with open("labels.txt", "w") as f:
    f.write("\n".join(labels))

print("Saved labels.txt")
